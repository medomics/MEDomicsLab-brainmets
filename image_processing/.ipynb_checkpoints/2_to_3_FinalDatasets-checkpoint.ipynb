{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Sequence\n",
    "from pathlib import Path\n",
    "import os\n",
    "import functools \n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/chens/practicum/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. filter records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_records(df,treatment_range=None,date_range=None,primary_use_list=None,age_range=None,met_range=None,return_list = False) -> Sequence[str]:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    filter the medical records based on \n",
    "        1. the number of treatments\n",
    "        2. first treatment date\n",
    "        3. the primary use, age and number of mets on the first treatment\n",
    "    \n",
    "    return a list of filenames if the parameter 'return_list' is True, otherwise return a DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Treatment count\n",
    "    droped_duplicates_date = df[['PiCare PatientID','StudyDateAnon']].drop_duplicates().dropna()\n",
    "    treat_count = droped_duplicates_date.groupby(['PiCare PatientID']).agg({'StudyDateAnon':'count'}).reset_index().rename(columns={'StudyDateAnon':'Treatment Count'})\n",
    "    filtered_treatment_num = treat_count[treat_count['Treatment Count'].between(treatment_range[0],treatment_range[1])]\n",
    "    filtered_df = filtered_treatment_num.merge(df,on='PiCare PatientID',how='left')\n",
    "\n",
    "    # First Treatment Date\n",
    "    first_treatment_date = filtered_df.groupby(['PiCare PatientID']).agg({'StudyDateAnon':'min'}).reset_index()\n",
    "    filtered_date = first_treatment_date[first_treatment_date['StudyDateAnon'].between(date_range[0],date_range[1])]\n",
    "    filtered_df = filtered_date.merge(filtered_df,on=['PiCare PatientID','StudyDateAnon'],how='left')[['PiCare PatientID',\n",
    "                                                                                          'StudyDateAnon',\n",
    "                                                                                          'Primary tumor Site',\n",
    "                                                                                          'Age primary diag']].drop_duplicates().dropna()\n",
    "    # Primary Use on First Treatment\n",
    "    if primary_use_list[0] != 'all': filtered_df = filtered_df[filtered_df['Primary tumor Site'].isin(primary_use_list)]\n",
    "    \n",
    "    # Age on First Treatment \n",
    "    filtered_df = filtered_df[filtered_df['Age primary diag'].between(age_range[0],age_range[1])]\n",
    "    \n",
    "    # Number of mets on First Treatment\n",
    "    num_of_mets = filtered_df.merge(df,on=['PiCare PatientID','StudyDateAnon','Primary tumor Site','Age primary diag'],how='left').assign(const=1).groupby(['PiCare PatientID','StudyDateAnon']).agg({'const':'count'}).rename(columns = {'const':'num of mets'}).reset_index()\n",
    "    filtered_mets = num_of_mets[num_of_mets['num of mets'].between(met_range[0],met_range[1])]\n",
    "    filtered_df = filtered_mets.merge(filtered_df,on = ['PiCare PatientID','StudyDateAnon'],how='left').dropna()\n",
    "    if return_list:\n",
    "        return [\n",
    "                str(filtered_df.iloc[i,0])\n",
    "                +'_'\n",
    "                +''.join(str(filtered_df.iloc[i,1]).split(' ')[0].split('-'))\n",
    "#                +'.npy'\n",
    "                for i in range(len(filtered_df))\n",
    "        ]\n",
    "    else: \n",
    "        return filtered_df[['PiCare PatientID','StudyDateAnon']].rename(columns={'StudyDateAnon':'First Study Date'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master_BrainMets_List_Anon_Sihan.xlsx\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chens/practicum/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/home/nanot/data/Master_BrainMets_List_Anon_June.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_df1 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [1,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df2 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [2,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df3 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [3,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df4 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [4,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df5 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [5,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df6 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [6,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df7 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [7,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df8 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [8,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df9 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [9,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n",
    "selected_df10 = filter_records(\n",
    "    df,\n",
    "    treatment_range = [10,100],\n",
    "    date_range = ['1900-01-01','2020-01-01'],\n",
    "    primary_use_list = ['all'],\n",
    "    met_range = [1,100],\n",
    "    age_range=[1,200],\n",
    "    return_list = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df_all = selected_df2+selected_df3+selected_df4+selected_df5+selected_df6+selected_df7+selected_df8+selected_df9+selected_df10\n",
    "len(selected_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = set(selected_df_all)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('/data/public/MIM_BMETS_V6/2_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image_mask_existence(file_path,name_list_from_excel):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This function is for checking existence of real images based on the Patient_ID list created by \n",
    "    filter_records function above\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    namelists = [path[2] for path in list(os.walk(file_path))[1:]]\n",
    "    namesets = []\n",
    "    for namelist in namelists:\n",
    "        namesets.append(set(['_'.join(name.split('_')[:2]) for name in namelist]))\n",
    "    \n",
    "    print(len(namesets[3]))\n",
    "    \n",
    "    #brain_masks_set, mets_masks, images, skll_stripped = namesets\n",
    "    existing_name_list = functools.reduce(lambda x,y:x.intersection(y),namesets)\n",
    "    \n",
    "    print(len(existing_name_list))\n",
    "    \n",
    "    result = [name for name in name_list_from_excel if name in existing_name_list]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n",
      "2133\n"
     ]
    }
   ],
   "source": [
    "existing_name_list = filter_image_mask_existence(file_path,selected_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_folders(target_folder):\n",
    "    \"\"\"\n",
    "    \n",
    "    Spliting the data filtered above into train, validation and test sets.\n",
    "    Creating a folder to store this subset.\n",
    "    \n",
    "    \"\"\"\n",
    "    main_path = Path('/data/public/MIM_BMETS_V6/3_final_datasets/')\n",
    "    target_folder = main_path/target_folder\n",
    "    target_folder.mkdir()\n",
    "    for name in ['training','validation','testing']:\n",
    "        (target_folder/name).mkdir()\n",
    "        for filetype in ['brain_masks','images','mets_masks','skull_stripped']:\n",
    "            (target_folder/name/filetype).mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_spliting(namelist,train_size,validation_size):\n",
    "    train,validation_test = train_test_split(existing_name_list,train_size=train_size,shuffle=True)\n",
    "    validation,test = train_test_split(validation_test,train_size=validation_size/(1-train_size),shuffle=True)\n",
    "    print(validation_size/(1-train_size))\n",
    "    return train,validation,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_subsets(target_folder,train,validation,test):\n",
    "    original_path = Path('/data/public/MIM_BMETS_V6/2_processed')\n",
    "    main_path = Path('/data/public/MIM_BMETS_V6/3_final_datasets/')\n",
    "    target_folder = main_path/target_folder\n",
    "#     for name in ['training','validation','testing']:\n",
    "    for filetype in ['brain_masks','images','mets_masks','skull_stripped']:\n",
    "        for file in tqdm(os.listdir(original_path/filetype)):\n",
    "            if '_'.join(file.split('_')[:2]) in train:\n",
    "                copyfile(str(original_path/filetype/file),target_folder/'training'/filetype/file)\n",
    "            elif '_'.join(file.split('_')[:2]) in validation:\n",
    "                copyfile(str(original_path/filetype/file),target_folder/'validation'/filetype/file)\n",
    "            elif '_'.join(file.split('_')[:2]) in test:\n",
    "                copyfile(str(original_path/filetype/file),target_folder/'testing'/filetype/file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder='re_treatments_1.5x1.5x3_256x256x64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "creating_folders(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "train,validation,test = data_spliting(existing_name_list,0.7,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "346\n",
      "74\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(existing_name_list))\n",
    "print(len(train))\n",
    "print(len(validation))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:35<00:00, 59.52it/s]\n",
      "100%|██████████| 2133/2133 [00:36<00:00, 58.73it/s] \n",
      "100%|██████████| 2133/2133 [00:36<00:00, 58.52it/s] \n",
      "100%|██████████| 2133/2133 [00:35<00:00, 60.31it/s] \n"
     ]
    }
   ],
   "source": [
    "saving_subsets(target_folder,train,validation,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ventricle",
   "language": "python",
   "name": "ventricle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
