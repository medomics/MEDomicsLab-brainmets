{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../image_processing/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    \n",
    "# plt.style.use(\"seaborn\")\n",
    "# sns.set(font_scale=1)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gc\n",
    "import functools \n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from apex import amp\n",
    "import dill\n",
    "\n",
    "import os, glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from resize import *\n",
    "# from unet3d.model import ResidualUNet3D\n",
    "# from unet3d.losses import *\n",
    "# from unet3d.utils import create_feature_maps\n",
    "# from unet3d.buildingblocks import Encoder, Decoder, FinalConv, ExtResNetBlock, SingleConv\n",
    "\n",
    "# from fastai.vision import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('./')\n",
    "train_img_path = data_path/'./manuscript_1_datasets/first_tx_allmets_0-0.5cc/training/fake_skull_stripped_1x1x3'\n",
    "train_mask_path = data_path/'./manuscript_1_datasets/first_tx_allmets_0-0.5cc/training/fake_mets_masks_1x1x3'\n",
    "valid_img_path = data_path/'./manuscript_1_datasets/first_tx_allmets_0-0.5cc/validation/skull_stripped_1x1x3'\n",
    "valid_mask_path = data_path/'./manuscript_1_datasets/first_tx_allmets_0-0.5cc/validation/mets_masks_1x1x3'\n",
    "test_img_path = data_path/'./manuscript_1_datasets/first_tx_allmets_0-0.5cc/testing/skull_stripped_1x1x3'\n",
    "test_mask_path = data_path/'./manuscript_1_datasets/first_tx_allmets_0-0.5cc/testing/mets_masks_1x1x3'\n",
    "\n",
    "cuda1 = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_files = sorted([str(train_img_path/file) for file in os.listdir(train_img_path)])\n",
    "train_mask_files = sorted([str(train_mask_path/mask) for mask in os.listdir(train_mask_path)])\n",
    "valid_img_files = sorted([str(valid_img_path/file) for file in os.listdir(valid_img_path)])\n",
    "valid_mask_files = sorted([str(valid_mask_path/mask) for mask in os.listdir(valid_mask_path)])\n",
    "test_img_files = sorted([str(test_img_path/file) for file in os.listdir(test_img_path)])\n",
    "test_mask_files = sorted([str(test_mask_path/mask) for mask in os.listdir(test_mask_path)])\n",
    "img_files = sorted(train_img_files+valid_img_files+test_img_files)\n",
    "mask_files = sorted(train_mask_files+valid_mask_files+test_mask_files)\n",
    "img_names = ['_'.join(file.split('/')[-1].split('_')[0:2]) for file in img_files]\n",
    "mask_names = ['_'.join(file.split('/')[-1].split('_')[0:2]) for file in mask_files]\n",
    "assert img_names==mask_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_crop_to_tensor(file,target_d=None,target_h=None,target_w=None):\n",
    "    img = np.load(file)\n",
    "    d, h, w = img.shape\n",
    "    if (target_d == None):\n",
    "        target_d = d\n",
    "    if (target_h == None):\n",
    "        target_h = h\n",
    "    if (target_w == None):\n",
    "        target_w = w\n",
    "    img = torch.from_numpy(xyz_pad(np.load(file),target_d,target_h,target_w)).type(torch.float)\n",
    "    return img\n",
    "\n",
    "class MetDataSet(Dataset):\n",
    "    def __init__(self,img_files,mask_files):\n",
    "        self.img_files = img_files\n",
    "        self.mask_files = mask_files\n",
    "        self.img_names = ['_'.join(file.split('/')[-1].split('_')[0:2]) for file in self.img_files]\n",
    "        self.mask_names = ['_'.join(file.split('/')[-1].split('_')[0:2]) for file in self.mask_files]\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    def __getitem__(self,idx):\n",
    "        img = read_and_crop_to_tensor(self.img_files[idx],64,256,256).unsqueeze(0)\n",
    "        mask = read_and_crop_to_tensor(self.mask_files[idx],64,256,256).unsqueeze(0)\n",
    "        return img.to(cuda1), mask.to(cuda1)\n",
    "    def get_name(self,idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        mask_name = self.mask_names[idx]\n",
    "        return img_name,mask_name\n",
    "    \n",
    "def show_single_pair(img,mask,index):\n",
    "    figs,axes = plt.subplots(1,2)\n",
    "    axes[0].imshow(img.cpu()[index])\n",
    "    axes[1].imshow(mask.cpu()[index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_img_files = [file for file in img_files if '/aug' in file]\n",
    "# aug_mask_files = [file for file in mask_files if '/aug' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 slices with mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MetDataSet(img_files,mask_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    img = train_dataset[i][0][0]\n",
    "    mask = train_dataset[i][1][0]\n",
    "    print(train_dataset.get_name(i)[0])\n",
    "    show_single_pair(img,mask,mask.argmax()//(256*256)+1)\n",
    "    show_single_pair(img,mask,mask.argmax()//(256*256)+2)\n",
    "#     plt.title(train_dataset.get_name(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_single_pair(img,mask,index):\n",
    "    figs,axes = plt.subplots(1,2)\n",
    "    axes[0].imshow(img[index])\n",
    "    axes[1].imshow(mask[index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manuscript_1_datasets/first_tx_allmets_0-0.5cc/training/fake_skull_stripped_1x1x3/BrainMets-UCSF-00274_19990927.npy48.npy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img)):\n",
    "    show_single_pair(read_and_crop_to_tensor(train_img_files[1],64,256,256),read_and_crop_to_tensor(train_mask_files[1],64,256,256),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
